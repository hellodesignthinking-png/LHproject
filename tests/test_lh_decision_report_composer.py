"""
Test LH Decision Report Composer

ëª©ì :
- LH Decision Report ìƒì„± ê²€ì¦
- Pass/Fail ì˜ˆì¸¡ ë¡œì§ í™•ì¸
- ê°œì„  ë°©ì•ˆ ìƒì„± ê²€ì¦
"""

import sys
sys.path.insert(0, '/home/user/webapp')

from app.services.report_composers.lh_decision_report_composer import LHDecisionReportComposer
from app.services.appraisal_context import AppraisalContextLock
from app.services.canonical_schema import CanonicalAppraisalResult, ZoningInfo


def create_mock_appraisal_context():
    """Mock AppraisalContextLock ìƒì„±"""
    
    from app.services.canonical_schema import (
        OfficialLandPrice, PremiumInfo, PremiumDetail,
        CalculationInfo, ConfidenceInfo, ConfidenceFactors,
        MetadataInfo
    )
    
    # Mock zoning info
    zoning = ZoningInfo(
        confirmed_type="ì œ2ì¢…ì¼ë°˜ì£¼ê±°ì§€ì—­",
        floor_area_ratio=250.0,
        building_coverage_ratio=50.0
    )
    
    # Create mock appraisal result directly
    result = CanonicalAppraisalResult(
        zoning=zoning,
        official_land_price=OfficialLandPrice(
            standard_price_per_sqm=5500000,
            reference_year=2024,
            reference_parcel="ì„œìš¸íŠ¹ë³„ì‹œ ë§ˆí¬êµ¬ XX-XX",
            distance_to_standard=100.0
        ),
        premium=PremiumInfo(
            development_potential=PremiumDetail(rate=0.045, rationale="ê°œë°œ ì ì¬ë ¥"),
            location_premium=PremiumDetail(rate=0.03, rationale="ì…ì§€ ìš°ìˆ˜"),
            policy_benefit=PremiumDetail(rate=0.015, rationale="ì •ì±… í˜œíƒ"),
            total_premium_rate=0.09
        ),
        calculation=CalculationInfo(
            base_price_per_sqm=5775000,
            premium_adjusted_per_sqm=6294750,
            land_area_sqm=660.0,
            final_appraised_total=4154535000
        ),
        confidence=ConfidenceInfo(
            score=0.80,
            factors=ConfidenceFactors(
                data_completeness=0.85,
                case_similarity=0.78,
                time_relevance=0.77
            )
        ),
        metadata=MetadataInfo()
    )
    
    # Create and lock context
    ctx = AppraisalContextLock()
    # Convert Pydantic model to dict for lock method
    ctx.lock(result.model_dump())
    
    return ctx


def create_mock_lh_result():
    """Mock LH Result ìƒì„±"""
    return {
        'decision': 'GO',
        'roi': 27.44,
        'construction_cost': 8400000000,
        'verified_cost': 627387750,
        'total_cost': 13182261750,
        'lh_purchase_price': 16800000000,
    }


def create_mock_ch3_scores():
    """Mock CH3 Scores ìƒì„±"""
    return {
        'overall_score': 85.0,
        'financial_feasibility': 90.0,
        'market_feasibility': 82.0,
    }


def create_mock_ch4_scores():
    """Mock CH4 Scores ìƒì„±"""
    return {
        'type_scores': {
            'í–‰ë³µì£¼íƒ': 15.2,
            'ì²­ë…„': 14.8,
            'ì‹ í˜¼ë¶€ë¶€': 14.2,
            'ì¼ë°˜': 13.5,
            'ê³µê³µì„ëŒ€': 12.8,
        }
    }


def test_lh_decision_report_generation():
    """Test LH Decision Report generation"""
    
    print("\n" + "="*80)
    print("ZeroSite v8.9 - LH Decision Report Composer Test")
    print("="*80)
    
    # Given
    print("\nğŸ“‹ STEP 1: Creating mock data...")
    appraisal_ctx = create_mock_appraisal_context()
    lh_result = create_mock_lh_result()
    ch3_scores = create_mock_ch3_scores()
    ch4_scores = create_mock_ch4_scores()
    
    print("   âœ… Mock data created")
    print(f"   Appraisal Context: LOCKED")
    print(f"   LH Decision: {lh_result['decision']}")
    print(f"   ROI: {lh_result['roi']:.2f}%")
    
    # When
    print("\nğŸ“‹ STEP 2: Generating LH Decision Report...")
    composer = LHDecisionReportComposer(appraisal_ctx, lh_result, ch3_scores, ch4_scores)
    report = composer.generate()
    
    # Then
    print("\nğŸ“‹ STEP 3: Verifying report structure...")
    
    assert 'report_id' in report, "Report ID missing"
    assert report['report_type'] == 'lh_decision_report', "Wrong report type"
    assert 'part_1_supply_type' in report, "Part 1 missing"
    assert 'part_2_purchase_price' in report, "Part 2 missing"
    assert 'part_3_pass_fail' in report, "Part 3 missing"
    assert 'part_4_improvements' in report, "Part 4 missing"
    
    print("   âœ… Report structure verified")
    
    # Verify Part 1: Supply Type Analysis
    print("\nğŸ“‹ STEP 4: Verifying Part 1 (ê³µê¸‰ìœ í˜• ì ì •ì„±)...")
    part1 = report['part_1_supply_type']
    
    assert 'recommended_type' in part1, "Recommended type missing"
    assert 'demand_score' in part1, "Demand score missing"
    assert 'suitability' in part1, "Suitability missing"
    
    print(f"   âœ… Part 1 verified")
    print(f"      Recommended Type: {part1['recommended_type']}")
    print(f"      Demand Score: {part1['normalized_score']:.1f}/100")
    print(f"      Suitability: {part1['suitability']} ({part1['suitability_text']})")
    
    # Verify Part 2: Purchase Price Analysis
    print("\nğŸ“‹ STEP 5: Verifying Part 2 (ë§¤ì…ê°€ ì ì •ì„±)...")
    part2 = report['part_2_purchase_price']
    
    assert 'land_appraisal' in part2, "Land appraisal missing"
    assert 'construction_cost' in part2, "Construction cost missing"
    assert 'lh_purchase_price' in part2, "LH purchase price missing"
    assert 'adequacy' in part2, "Adequacy missing"
    
    print(f"   âœ… Part 2 verified")
    print(f"      Land Appraisal: {part2['land_appraisal_formatted']}")
    print(f"      Construction Cost: {part2['construction_cost_formatted']}")
    print(f"      Total Cost: {part2['total_cost_formatted']}")
    print(f"      LH Purchase Price: {part2['lh_purchase_price_formatted']}")
    print(f"      Price Ratio: {part2['price_ratio']:.1f}%")
    print(f"      Adequacy: {part2['adequacy']} ({part2['adequacy_text']})")
    
    # Verify Part 3: Pass/Fail Prediction
    print("\nğŸ“‹ STEP 6: Verifying Part 3 (Pass/Fail ì˜ˆì¸¡)...")
    part3 = report['part_3_pass_fail']
    
    assert 'prediction' in part3, "Prediction missing"
    assert part3['prediction'] in ['PASS', 'CONDITIONAL', 'FAIL'], "Invalid prediction"
    assert 'pass_factors' in part3, "Pass factors missing"
    assert 'fail_risks' in part3, "Fail risks missing"
    
    print(f"   âœ… Part 3 verified")
    print(f"      Prediction: {part3['prediction_icon']} {part3['prediction']} ({part3['prediction_text']})")
    print(f"      Confidence: {part3['confidence_percentage']}%")
    print(f"      Overall Score: {part3['overall_score']}/100")
    
    print(f"\n      Pass Factors ({part3['pass_factors_count']}):")
    for factor in part3['pass_factors']:
        print(f"         {factor}")
    
    if part3['fail_risks']:
        print(f"\n      Fail Risks ({part3['fail_risks_count']}):")
        for risk in part3['fail_risks']:
            print(f"         {risk}")
    
    # Verify Part 4: Improvement Strategies
    print("\nğŸ“‹ STEP 7: Verifying Part 4 (ê°œì„  ë°©ì•ˆ)...")
    part4 = report['part_4_improvements']
    
    assert 'improvement_strategies' in part4, "Improvement strategies missing"
    assert 'alternative_scenarios' in part4, "Alternative scenarios missing"
    assert 'recommendation' in part4, "Recommendation missing"
    
    print(f"   âœ… Part 4 verified")
    print(f"      Improvement Strategies: {part4['improvement_count']}")
    print(f"      Alternative Scenarios: {len(part4['alternative_scenarios'])}")
    print(f"      Estimated Timeline: {part4['estimated_timeline']}")
    print(f"      Final Recommendation: {part4['recommendation']}")
    
    if part4['improvement_strategies']:
        print(f"\n      Strategies:")
        for strategy in part4['improvement_strategies']:
            print(f"         [{strategy['priority']}] {strategy['strategy']}")
            print(f"            Impact: {strategy['estimated_impact']}")
            print(f"            Timeline: {strategy['timeline']}")
    
    print("\n" + "="*80)
    print("âœ… ALL TESTS PASSED - LH Decision Report Composer Working Correctly")
    print("="*80)
    
    return report


if __name__ == "__main__":
    test_lh_decision_report_generation()

"""
ZeroSite v40.4 - Report Generation í†µí•© í…ŒìŠ¤íŠ¸

í…ŒìŠ¤íŠ¸ ëª©ì :
1. ë³´ê³ ì„œ 5ì¢… ì²´ê³„ ê²€ì¦
2. Landowner Brief (3p) ìƒì„± í…ŒìŠ¤íŠ¸
3. Report Type Validation ê²€ì¦
4. LH Review í†µí•© ê²€ì¦

Date: 2025-12-14
"""

import requests
import json
from typing import Dict, Any

BASE_URL = "http://localhost:8001"

class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    END = '\033[0m'


def print_test_header(test_name: str):
    print(f"\n{Colors.BLUE}{'='*80}")
    print(f"TEST: {test_name}")
    print(f"{'='*80}{Colors.END}")


def print_result(test_name: str, passed: bool, details: str = ""):
    status = f"{Colors.GREEN}âœ… PASS{Colors.END}" if passed else f"{Colors.RED}âŒ FAIL{Colors.END}"
    print(f"{status} - {test_name}")
    if details:
        print(f"  â””â”€ {details}")


def test_1_create_context_with_lh_review():
    """Test 1: Create context and run LH review"""
    print_test_header("Test 1: Context ìƒì„± ë° LH ì‹¬ì‚¬ì˜ˆì¸¡ ì‹¤í–‰")
    
    try:
        # Step 1: Create analysis context
        payload = {
            "address": "ì„œìš¸íŠ¹ë³„ì‹œ ê´€ì•…êµ¬ ì‹ ë¦¼ë™ 1524-8",
            "land_area_sqm": 650.0
        }
        
        response = requests.post(f"{BASE_URL}/api/v40.2/run-analysis", json=payload)
        response.raise_for_status()
        result = response.json()
        
        context_id = result.get("context_id")
        
        print_result(
            "Context Creation",
            True,
            f"Context ID: {context_id[:12]}..."
        )
        
        # Step 2: Run LH Review
        lh_payload = {
            "context_id": context_id,
            "housing_type": "ì²­ë…„",
            "target_units": 25
        }
        
        lh_response = requests.post(f"{BASE_URL}/api/v40/lh-review/predict", json=lh_payload)
        lh_response.raise_for_status()
        lh_result = lh_response.json()
        
        score = lh_result.get('predicted_score', 0)
        probability = lh_result.get('pass_probability', 0)
        
        print_result(
            "LH Review Prediction",
            score > 0,
            f"Score: {score}/100, Probability: {probability}%"
        )
        
        # Store LH review in context (simulate)
        # In production, this would be done automatically by the API
        
        return True, context_id
        
    except Exception as e:
        print_result("Context & LH Review", False, str(e))
        return False, None


def test_2_landowner_brief_generation(context_id: str):
    """Test 2: Generate Landowner Brief (3p) report"""
    print_test_header("Test 2: Landowner Brief (3p) ë³´ê³ ì„œ ìƒì„±")
    
    try:
        # Generate report
        response = requests.get(
            f"{BASE_URL}/api/v40.2/reports/{context_id}/landowner_brief"
        )
        response.raise_for_status()
        
        # Check response
        content_type = response.headers.get('Content-Type')
        content_length = len(response.content)
        
        passed = (
            content_type == 'application/pdf' and
            content_length > 10000  # At least 10KB
        )
        
        print_result(
            "Landowner Brief Generation",
            passed,
            f"Size: {content_length/1024:.1f}KB, Type: {content_type}"
        )
        
        # Save to file for manual inspection
        if passed:
            with open('/tmp/landowner_brief_test.pdf', 'wb') as f:
                f.write(response.content)
            print(f"  â””â”€ Saved to: /tmp/landowner_brief_test.pdf")
        
        return passed, response.content
        
    except Exception as e:
        print_result("Landowner Brief Generation", False, str(e))
        return False, None


def test_3_appraisal_v39_generation(context_id: str):
    """Test 3: Generate Appraisal v39 report (backward compatibility)"""
    print_test_header("Test 3: Appraisal v39 (í•˜ìœ„ í˜¸í™˜) ë³´ê³ ì„œ ìƒì„±")
    
    try:
        response = requests.get(
            f"{BASE_URL}/api/v40.2/reports/{context_id}/appraisal_v39"
        )
        response.raise_for_status()
        
        content_type = response.headers.get('Content-Type')
        content_length = len(response.content)
        
        passed = (
            content_type == 'application/pdf' and
            content_length > 50000  # At least 50KB (larger than landowner brief)
        )
        
        print_result(
            "Appraisal v39 Generation",
            passed,
            f"Size: {content_length/1024:.1f}KB, Type: {content_type}"
        )
        
        return passed, response.content
        
    except Exception as e:
        print_result("Appraisal v39 Generation", False, str(e))
        return False, None


def test_4_invalid_report_type(context_id: str):
    """Test 4: Test invalid report type handling"""
    print_test_header("Test 4: ì˜ëª»ëœ ë³´ê³ ì„œ íƒ€ì… ì²˜ë¦¬")
    
    try:
        # Try to generate a report with invalid type
        response = requests.get(
            f"{BASE_URL}/api/v40.2/reports/{context_id}/invalid_type"
        )
        
        # Should return 400 error
        passed = response.status_code == 400
        
        print_result(
            "Invalid Report Type Handling",
            passed,
            f"Status Code: {response.status_code} (Expected 400)"
        )
        
        return passed, None
        
    except Exception as e:
        # If exception is raised, check if it's the expected error
        passed = "400" in str(e) or "ì§€ì›í•˜ì§€ ì•ŠëŠ”" in str(e)
        print_result("Invalid Report Type Handling", passed, str(e))
        return passed, None


def test_5_future_report_types(context_id: str):
    """Test 5: Test future report types (not yet implemented)"""
    print_test_header("Test 5: í–¥í›„ ì§€ì› ì˜ˆì • ë³´ê³ ì„œ íƒ€ì…")
    
    future_types = ["lh_submission", "policy_impact", "developer_feasibility"]
    results = []
    
    for report_type in future_types:
        try:
            response = requests.get(
                f"{BASE_URL}/api/v40.2/reports/{context_id}/{report_type}"
            )
            
            # Should return 501 (Not Implemented)
            passed = response.status_code == 501
            results.append(passed)
            
            status_text = "âœ… Correct (501)" if passed else f"âŒ Wrong ({response.status_code})"
            print(f"  â€¢ {report_type}: {status_text}")
            
        except Exception as e:
            passed = "501" in str(e) or "ì§€ì› ì˜ˆì •" in str(e)
            results.append(passed)
            print(f"  â€¢ {report_type}: {'âœ…' if passed else 'âŒ'}")
    
    all_passed = all(results)
    print_result(
        "Future Report Types",
        all_passed,
        f"{sum(results)}/{len(results)} types correctly handled"
    )
    
    return all_passed, None


def test_6_report_validation():
    """Test 6: Test report validation without LH review"""
    print_test_header("Test 6: LH Review ì—†ì´ ë³´ê³ ì„œ ìš”ì²­")
    
    try:
        # Create context without LH review
        payload = {
            "address": "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ ì—­ì‚¼ë™ 123",
            "land_area_sqm": 500.0
        }
        
        response = requests.post(f"{BASE_URL}/api/v40.2/run-analysis", json=payload)
        response.raise_for_status()
        result = response.json()
        
        context_id = result.get("context_id")
        
        # Try to generate Landowner Brief (should still work but with warning)
        report_response = requests.get(
            f"{BASE_URL}/api/v40.2/reports/{context_id}/landowner_brief"
        )
        
        # Should succeed (LH review is optional for landowner brief)
        passed = report_response.status_code == 200
        
        print_result(
            "Report without LH Review",
            passed,
            "ë³´ê³ ì„œ ìƒì„± ì„±ê³µ (LH Review ì„ íƒì‚¬í•­)"
        )
        
        return passed, context_id
        
    except Exception as e:
        print_result("Report without LH Review", False, str(e))
        return False, None


def run_all_tests():
    """Run all v40.4 report generation tests"""
    print(f"\n{Colors.BLUE}{'='*80}")
    print("ZeroSite v40.4 - Report Generation Tests")
    print("ë³´ê³ ì„œ 5ì¢… ì²´ê³„ í†µí•© í…ŒìŠ¤íŠ¸")
    print(f"{'='*80}{Colors.END}\n")
    
    results = []
    
    # Test 1: Create Context + LH Review
    passed, context_id = test_1_create_context_with_lh_review()
    results.append(("Context & LH Review", passed))
    
    if not passed or not context_id:
        print(f"\n{Colors.RED}âŒ Context creation failed. Stopping tests.{Colors.END}")
        return
    
    # Test 2: Landowner Brief
    passed, _ = test_2_landowner_brief_generation(context_id)
    results.append(("Landowner Brief (3p)", passed))
    
    # Test 3: Appraisal v39 (backward compatibility)
    passed, _ = test_3_appraisal_v39_generation(context_id)
    results.append(("Appraisal v39 (í•˜ìœ„ í˜¸í™˜)", passed))
    
    # Test 4: Invalid report type
    passed, _ = test_4_invalid_report_type(context_id)
    results.append(("Invalid Type Handling", passed))
    
    # Test 5: Future report types
    passed, _ = test_5_future_report_types(context_id)
    results.append(("Future Types (501)", passed))
    
    # Test 6: Report without LH review
    passed, _ = test_6_report_validation()
    results.append(("Without LH Review", passed))
    
    # Summary
    print(f"\n{Colors.BLUE}{'='*80}")
    print("TEST SUMMARY")
    print(f"{'='*80}{Colors.END}\n")
    
    passed_count = sum(1 for _, passed in results if passed)
    total_count = len(results)
    
    for test_name, passed in results:
        status = f"{Colors.GREEN}âœ… PASS{Colors.END}" if passed else f"{Colors.RED}âŒ FAIL{Colors.END}"
        print(f"{status} - {test_name}")
    
    print(f"\n{Colors.BLUE}Total: {passed_count}/{total_count} tests passed{Colors.END}")
    
    if passed_count == total_count:
        print(f"\n{Colors.GREEN}ğŸ‰ ALL TESTS PASSED! v40.4 Report System is working!{Colors.END}")
    else:
        print(f"\n{Colors.YELLOW}âš ï¸ Some tests failed. Please review the results above.{Colors.END}")
    
    # Additional info
    print(f"\n{Colors.BLUE}ğŸ“Š Report Status:{Colors.END}")
    print("  âœ… Landowner Brief (3p) - Implemented")
    print("  â³ LH Submission (10~15p) - v40.5 ì˜ˆì •")
    print("  â³ Policy Impact (15p) - v40.5 ì˜ˆì •")
    print("  â³ Developer Feasibility (15~20p) - v40.5 ì˜ˆì •")
    print("  â³ Extended Professional (25~40p) - v40.5 ì˜ˆì •")
    print("  âœ… Appraisal v39 (23~30p) - í•˜ìœ„ í˜¸í™˜ ìœ ì§€")


if __name__ == "__main__":
    run_all_tests()

"""
v1.6.0: RUN_ID Data Integration Service
ì‹¤ì œ RUN_ID ë°ì´í„° ì¡°íšŒ ë° ê´€ë¦¬
"""

from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta
from pydantic import BaseModel
import logging

from app.services.context_storage import context_storage
from app.models.context_snapshot import ContextSnapshot
from app.database import SessionLocal

logger = logging.getLogger(__name__)


class RunIdInfo(BaseModel):
    """RUN_ID ì •ë³´ ëª¨ë¸"""
    run_id: str
    address: Optional[str] = None
    pnu: Optional[str] = None
    land_area: Optional[float] = None
    zone: Optional[str] = None
    created_at: datetime
    status: str = "ACTIVE"
    has_data: bool = True
    
    class Config:
        json_schema_extra = {
            "example": {
                "run_id": "RUN_20260101_ABC123",
                "address": "ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123",
                "pnu": "1168010100",
                "land_area": 500.0,
                "zone": "ì œ2ì¢…ì¼ë°˜ì£¼ê±°ì§€ì—­",
                "created_at": "2026-01-01T12:00:00",
                "status": "ACTIVE",
                "has_data": True
            }
        }


class RunIdDataService:
    """
    RUN_ID ë°ì´í„° í†µí•© ì„œë¹„ìŠ¤
    
    ë°ì´í„° ì†ŒìŠ¤:
    1. Context Storage (Redis/Memory)
    2. Database Snapshots
    3. í…ŒìŠ¤íŠ¸ ë°ì´í„° (DEV ëª¨ë“œ)
    """
    
    def __init__(self):
        self.test_run_ids = self._generate_test_run_ids()
    
    def _generate_test_run_ids(self) -> List[RunIdInfo]:
        """í…ŒìŠ¤íŠ¸ìš© RUN_ID ìƒì„± (DEV ëª¨ë“œ)"""
        base_time = datetime.now()
        
        return [
            RunIdInfo(
                run_id="TEST_6REPORT",
                address="ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123",
                pnu="1168010100",
                land_area=500.0,
                zone="ì œ2ì¢…ì¼ë°˜ì£¼ê±°ì§€ì—­",
                created_at=base_time - timedelta(hours=2),
                status="ACTIVE",
                has_data=True
            ),
            RunIdInfo(
                run_id="RUN_20260101_SAMPLE_A",
                address="ì„œìš¸ì‹œ ì„œì´ˆêµ¬ ë°˜í¬ëŒ€ë¡œ 58",
                pnu="1165010100",
                land_area=800.0,
                zone="ì œ3ì¢…ì¼ë°˜ì£¼ê±°ì§€ì—­",
                created_at=base_time - timedelta(days=1),
                status="ACTIVE",
                has_data=True
            ),
            RunIdInfo(
                run_id="RUN_20260101_SAMPLE_B",
                address="ê²½ê¸°ë„ ì„±ë‚¨ì‹œ ë¶„ë‹¹êµ¬ íŒêµì—­ë¡œ 235",
                pnu="4113510100",
                land_area=1200.0,
                zone="ì¤€ì£¼ê±°ì§€ì—­",
                created_at=base_time - timedelta(days=2),
                status="ACTIVE",
                has_data=True
            ),
            RunIdInfo(
                run_id="RUN_20260101_SAMPLE_C",
                address="ì¸ì²œì‹œ ì—°ìˆ˜êµ¬ ì†¡ë„ë™ 123",
                pnu="2871510100",
                land_area=600.0,
                zone="ì œ2ì¢…ì¼ë°˜ì£¼ê±°ì§€ì—­",
                created_at=base_time - timedelta(days=3),
                status="ACTIVE",
                has_data=True
            ),
            RunIdInfo(
                run_id="RUN_20260101_SAMPLE_D",
                address="ëŒ€ì „ì‹œ ìœ ì„±êµ¬ ëŒ€í•™ë¡œ 99",
                pnu="3023010100",
                land_area=450.0,
                zone="ì¤€ì£¼ê±°ì§€ì—­",
                created_at=base_time - timedelta(days=5),
                status="ACTIVE",
                has_data=True
            )
        ]
    
    def get_all_run_ids(
        self,
        status: Optional[str] = None,
        limit: int = 100
    ) -> List[RunIdInfo]:
        """
        ëª¨ë“  RUN_ID ì¡°íšŒ
        
        Args:
            status: ìƒíƒœ í•„í„° (ACTIVE, EXPIRED, etc.)
            limit: ìµœëŒ€ ì¡°íšŒ ê°œìˆ˜
            
        Returns:
            RUN_ID ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        run_ids = []
        
        # 1. Databaseì—ì„œ ì¡°íšŒ
        try:
            db_run_ids = self._get_from_database(limit=limit)
            run_ids.extend(db_run_ids)
        except Exception as e:
            logger.warning(f"Failed to load RUN_IDs from database: {e}")
        
        # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ê°€ (ê°œë°œ ëª¨ë“œ)
        import os
        if os.getenv("ZEROSITE_ENV", "dev").lower() == "dev":
            run_ids.extend(self.test_run_ids)
        
        # 3. ìƒíƒœ í•„í„°ë§
        if status:
            run_ids = [r for r in run_ids if r.status == status]
        
        # 4. ìƒì„±ì¼ ê¸°ì¤€ ì •ë ¬ (ìµœì‹ ìˆœ)
        run_ids.sort(key=lambda x: x.created_at, reverse=True)
        
        # 5. ì¤‘ë³µ ì œê±° (run_id ê¸°ì¤€)
        seen = set()
        unique_run_ids = []
        for r in run_ids:
            if r.run_id not in seen:
                seen.add(r.run_id)
                unique_run_ids.append(r)
        
        return unique_run_ids[:limit]
    
    def _get_from_database(self, limit: int = 100) -> List[RunIdInfo]:
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ RUN_ID ì¡°íšŒ"""
        run_ids = []
        
        try:
            with SessionLocal() as db:
                # ContextSnapshotì—ì„œ ì¡°íšŒ
                snapshots = db.query(ContextSnapshot).order_by(
                    ContextSnapshot.created_at.desc()
                ).limit(limit).all()
                
                for snapshot in snapshots:
                    # JSON ë°ì´í„°ì—ì„œ ì •ë³´ ì¶”ì¶œ
                    try:
                        context_data = snapshot.context_data
                        
                        run_ids.append(RunIdInfo(
                            run_id=snapshot.context_id,
                            address=context_data.get('address'),
                            pnu=context_data.get('pnu'),
                            land_area=context_data.get('land_area'),
                            zone=context_data.get('zone'),
                            created_at=snapshot.created_at,
                            status="ACTIVE",
                            has_data=True
                        ))
                    except Exception as e:
                        logger.warning(f"Failed to parse snapshot {snapshot.context_id}: {e}")
                        continue
        
        except Exception as e:
            logger.error(f"Database query failed: {e}")
        
        return run_ids
    
    def get_run_id_info(self, run_id: str) -> Optional[RunIdInfo]:
        """
        íŠ¹ì • RUN_ID ì •ë³´ ì¡°íšŒ
        
        Args:
            run_id: RUN_ID
            
        Returns:
            RUN_ID ì •ë³´ ë˜ëŠ” None
        """
        # 1. Database ì¡°íšŒ
        try:
            with SessionLocal() as db:
                snapshot = db.query(ContextSnapshot).filter(
                    ContextSnapshot.context_id == run_id
                ).first()
                
                if snapshot:
                    context_data = snapshot.context_data
                    return RunIdInfo(
                        run_id=snapshot.context_id,
                        address=context_data.get('address'),
                        pnu=context_data.get('pnu'),
                        land_area=context_data.get('land_area'),
                        zone=context_data.get('zone'),
                        created_at=snapshot.created_at,
                        status="ACTIVE",
                        has_data=True
                    )
        except Exception as e:
            logger.warning(f"Failed to query database for {run_id}: {e}")
        
        # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì¡°íšŒ
        for test_run in self.test_run_ids:
            if test_run.run_id == run_id:
                return test_run
        
        return None
    
    def search_run_ids(
        self,
        query: str,
        limit: int = 20
    ) -> List[RunIdInfo]:
        """
        RUN_ID ê²€ìƒ‰ (ì£¼ì†Œ, PNU, RUN_IDë¡œ ê²€ìƒ‰)
        
        Args:
            query: ê²€ìƒ‰ì–´
            limit: ìµœëŒ€ ê²°ê³¼ ê°œìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        all_run_ids = self.get_all_run_ids(limit=100)
        
        # ê²€ìƒ‰ì–´ ì •ê·œí™” (ê³µë°± ì œê±°ë§Œ, lowerëŠ” í•œê¸€ì— ë¬¸ì œ ì—†ìŒ)
        query_normalized = query.strip()
        
        logger.info(f"ğŸ” Searching for: '{query_normalized}' (total RUN_IDs: {len(all_run_ids)})")
        
        # í•„í„°ë§
        results = []
        for run_id_info in all_run_ids:
            # RUN_ID ë§¤ì¹­ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            if query_normalized.lower() in run_id_info.run_id.lower():
                results.append(run_id_info)
                logger.debug(f"  âœ“ Matched RUN_ID: {run_id_info.run_id}")
                continue
            
            # ì£¼ì†Œ ë§¤ì¹­ (í•œê¸€ì€ ëŒ€ì†Œë¬¸ì ì—†ìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë¹„êµ)
            if run_id_info.address and query_normalized in run_id_info.address:
                results.append(run_id_info)
                logger.debug(f"  âœ“ Matched Address: {run_id_info.address}")
                continue
            
            # PNU ë§¤ì¹­
            if run_id_info.pnu and query_normalized in run_id_info.pnu:
                results.append(run_id_info)
                logger.debug(f"  âœ“ Matched PNU: {run_id_info.pnu}")
                continue
        
        logger.info(f"ğŸ” Search results: {len(results)} items found")
        return results[:limit]
    
    def get_run_id_statistics(self) -> Dict[str, Any]:
        """
        RUN_ID í†µê³„ ì¡°íšŒ
        
        Returns:
            í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        all_run_ids = self.get_all_run_ids(limit=1000)
        
        # ìƒíƒœë³„ ì¹´ìš´íŠ¸
        status_count = {}
        for r in all_run_ids:
            status_count[r.status] = status_count.get(r.status, 0) + 1
        
        # ì§€ì—­ë³„ ì¹´ìš´íŠ¸ (ì£¼ì†Œ ê¸°ì¤€)
        region_count = {}
        for r in all_run_ids:
            if r.address:
                # ì²« ë‹¨ì–´ ì¶”ì¶œ (ì˜ˆ: "ì„œìš¸ì‹œ", "ê²½ê¸°ë„")
                region = r.address.split()[0] if r.address.split() else "ê¸°íƒ€"
                region_count[region] = region_count.get(region, 0) + 1
        
        # ìµœê·¼ ìƒì„±ëœ RUN_ID
        recent = sorted(all_run_ids, key=lambda x: x.created_at, reverse=True)[:5]
        
        return {
            "total_count": len(all_run_ids),
            "active_count": status_count.get("ACTIVE", 0),
            "by_status": status_count,
            "by_region": region_count,
            "recent": [r.run_id for r in recent]
        }


# Singleton instance
_service_instance: Optional[RunIdDataService] = None


def get_run_id_service() -> RunIdDataService:
    """RUN_ID ë°ì´í„° ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤"""
    global _service_instance
    if _service_instance is None:
        _service_instance = RunIdDataService()
    return _service_instance

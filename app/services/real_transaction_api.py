"""
ZeroSite v18 Phase 3 - Real Transaction API Service
====================================================
êµ­í† êµí†µë¶€ ì‹¤ê±°ë˜ê°€ API í†µí•© ì„œë¹„ìŠ¤

Features:
- í† ì§€ ì‹¤ê±°ë˜ê°€ ì¡°íšŒ (ìµœê·¼ 1ë…„, ë°˜ê²½ 1km, Top 10)
- ê±´ì¶•ë¬¼ ë§¤ë§¤ì‚¬ë¡€ ì¡°íšŒ (ì˜¤í”¼ìŠ¤í…”, ì—°ë¦½ë‹¤ì„¸ëŒ€, ë‹¨ë…ë‹¤ê°€êµ¬)
- ê±°ë¦¬ ê¸°ë°˜ í•„í„°ë§ ë° ì •ë ¬
- í‰ê·  ë‹¨ê°€ ìë™ ê³„ì‚°
"""

import httpx
import asyncio
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import logging
import xml.etree.ElementTree as ET
from math import radians, sin, cos, sqrt, atan2

# Import caching system
try:
    from app.services.real_transaction_cache import get_cache
    CACHE_ENABLED = True
except ImportError:
    CACHE_ENABLED = False
    logger.warning("âš ï¸ Cache module not found - running without cache")

logger = logging.getLogger(__name__)


@dataclass
class LandTransaction:
    """í† ì§€ ê±°ë˜ ì‚¬ë¡€"""
    address: str
    area_m2: float
    price_krw: float
    unit_krw_m2: float
    deal_date: str
    use_zone: Optional[str] = None
    
    def to_dict(self):
        return asdict(self)


@dataclass
class BuildingTransaction:
    """ê±´ì¶•ë¬¼ ë§¤ë§¤ ì‚¬ë¡€"""
    name: str
    address: str
    area_m2: float
    price_krw: float
    unit_krw_m2: float
    deal_date: str
    building_type: Optional[str] = None
    
    def to_dict(self):
        return asdict(self)


class RealTransactionAPI:
    """
    êµ­í† êµí†µë¶€ ì‹¤ê±°ë˜ê°€ API í†µí•© ì„œë¹„ìŠ¤
    
    APIs:
    - í† ì§€ ë§¤ë§¤: RTMSDataSvcLandTrade
    - ì˜¤í”¼ìŠ¤í…” ë§¤ë§¤: RTMSDataSvcOffiTrade
    - ì—°ë¦½ë‹¤ì„¸ëŒ€ ë§¤ë§¤: RTMSDataSvcRHTrade
    - ë‹¨ë…ë‹¤ê°€êµ¬ ë§¤ë§¤: RTMSDataSvcSHTrade
    """
    
    # API Keys
    API_KEY = "5158584967f97600a71afc331e848ad6c8154524d2266a6ad62c22c5f5c9ad87"
    
    # Endpoints
    LAND_ENDPOINT = "https://apis.data.go.kr/1613000/RTMSDataSvcLandTrade/getRTMSDataSvcLandTrade"
    OFFICETEL_ENDPOINT = "https://apis.data.go.kr/1613000/RTMSDataSvcOffiTrade/getRTMSDataSvcOffiTrade"
    TOWNHOUSE_ENDPOINT = "https://apis.data.go.kr/1613000/RTMSDataSvcRHTrade/getRTMSDataSvcRHTrade"
    SINGLEHOUSE_ENDPOINT = "https://apis.data.go.kr/1613000/RTMSDataSvcSHTrade/getRTMSDataSvcSHTrade"
    
    def __init__(self, enable_cache: bool = True):
        self.api_key = self.API_KEY
        self.cache_enabled = enable_cache and CACHE_ENABLED
        self.cache = get_cache() if self.cache_enabled else None
        
        logger.info("=" * 80)
        logger.info("ğŸŒ RealTransactionAPI initialized")
        logger.info(f"   Land API: {self.LAND_ENDPOINT[:50]}...")
        logger.info(f"   Building APIs: 3 endpoints configured")
        logger.info(f"   Cache: {'âœ… ENABLED' if self.cache_enabled else 'âŒ DISABLED'}")
        logger.info("=" * 80)
    
    def _calculate_distance_m(self, lat1: float, lon1: float, lat2: float, lon2: float) -> float:
        """ë‘ ì¢Œí‘œ ê°„ ê±°ë¦¬ ê³„ì‚° (ë¯¸í„°)"""
        R = 6371000  # ì§€êµ¬ ë°˜ê²½ (ë¯¸í„°)
        
        lat1_rad = radians(lat1)
        lat2_rad = radians(lat2)
        dlat = radians(lat2 - lat1)
        dlon = radians(lon2 - lon1)
        
        a = sin(dlat/2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon/2)**2
        c = 2 * atan2(sqrt(a), sqrt(1-a))
        
        return R * c
    
    def _parse_xml_response(self, xml_text: str) -> List[Dict]:
        """XML ì‘ë‹µ íŒŒì‹±"""
        try:
            root = ET.fromstring(xml_text)
            
            # Check result code
            result_code = root.find('.//resultCode')
            if result_code is not None and result_code.text != '00':
                result_msg = root.find('.//resultMsg')
                logger.warning(f"API Error: {result_msg.text if result_msg is not None else 'Unknown'}")
                return []
            
            # Parse items
            items = []
            for item in root.findall('.//item'):
                item_dict = {}
                for child in item:
                    item_dict[child.tag] = child.text
                items.append(item_dict)
            
            return items
            
        except Exception as e:
            logger.error(f"XML parsing failed: {e}")
            return []
    
    async def fetch_land_transactions(
        self,
        lawd_cd: str,  # ë²•ì •ë™ì½”ë“œ (ì„œìš¸ 11, ê²½ê¸° 41, etc)
        deal_ymd: str,  # YYYYMM
        center_lat: float,
        center_lon: float,
        radius_m: int = 1000
    ) -> List[LandTransaction]:
        """
        í† ì§€ ì‹¤ê±°ë˜ê°€ ì¡°íšŒ (ìºì‹± ì§€ì›)
        
        Args:
            lawd_cd: ë²•ì •ë™ì½”ë“œ (ì• 2ìë¦¬, ì„œìš¸=11, ê²½ê¸°=41)
            deal_ymd: ê±°ë˜ë…„ì›” (YYYYMM)
            center_lat: ì¤‘ì‹¬ ìœ„ë„
            center_lon: ì¤‘ì‹¬ ê²½ë„
            radius_m: ê²€ìƒ‰ ë°˜ê²½ (ë¯¸í„°)
        
        Returns:
            LandTransaction ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"ğŸï¸  Fetching land transactions: lawd={lawd_cd}, date={deal_ymd}, radius={radius_m}m")
        
        # Try cache first
        if self.cache_enabled:
            cached_data = self.cache.get('land', lawd_cd, deal_ymd)
            if cached_data:
                transactions = [LandTransaction(**t) for t in cached_data]
                logger.info(f"   âœ… Loaded {len(transactions)} land transactions from cache")
                return transactions[:10]
        
        params = {
            'serviceKey': self.api_key,
            'LAWD_CD': lawd_cd,
            'DEAL_YMD': deal_ymd,
            'numOfRows': '100',
            'pageNo': '1'
        }
        
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(self.LAND_ENDPOINT, params=params)
                response.raise_for_status()
                
                items = self._parse_xml_response(response.text)
                logger.info(f"   Retrieved {len(items)} land records from API")
                
                transactions = []
                for item in items:
                    try:
                        # Extract data
                        area = float(item.get('plottgAr', '0'))  # ëŒ€ì§€ë©´ì 
                        price = int(item.get('dealAmount', '0').replace(',', '')) * 10000  # ê±°ë˜ê¸ˆì•¡ (ë§Œì› â†’ ì›)
                        
                        if area <= 0 or price <= 0:
                            continue
                        
                        unit = price / area
                        
                        # Build address
                        sgg_nm = item.get('sggNm', '')  # ì‹œêµ°êµ¬ëª…
                        umd_nm = item.get('umdNm', '')  # ìë©´ë™ëª…
                        jibun = item.get('jibun', '')   # ì§€ë²ˆ
                        address = f"{sgg_nm} {umd_nm} {jibun}".strip()
                        
                        # Deal date
                        deal_year = item.get('dealYear', '')
                        deal_month = item.get('dealMonth', '').zfill(2)
                        deal_day = item.get('dealDay', '').zfill(2)
                        deal_date = f"{deal_year}.{deal_month}.{deal_day}"
                        
                        transactions.append(LandTransaction(
                            address=address,
                            area_m2=area,
                            price_krw=price,
                            unit_krw_m2=unit,
                            deal_date=deal_date,
                            use_zone=None  # API doesn't provide this
                        ))
                        
                    except Exception as e:
                        logger.warning(f"Failed to parse land item: {e}")
                        continue
                
                # Sort by date (most recent first)
                transactions.sort(key=lambda x: x.deal_date, reverse=True)
                
                # Take top 10
                top_transactions = transactions[:10]
                
                logger.info(f"   âœ… Parsed {len(top_transactions)} land transactions")
                if top_transactions:
                    avg_unit = sum(t.unit_krw_m2 for t in top_transactions) / len(top_transactions)
                    logger.info(f"   ğŸ“Š Average land price: {avg_unit/10000:.0f}ë§Œì›/ã¡")
                
                # Save to cache
                if self.cache_enabled and top_transactions:
                    cache_data = [t.to_dict() for t in top_transactions]
                    self.cache.set('land', lawd_cd, deal_ymd, cache_data)
                
                return top_transactions
                
        except Exception as e:
            logger.error(f"âŒ Land transaction API failed: {e}")
            return []
    
    async def fetch_building_transactions(
        self,
        lawd_cd: str,
        deal_ymd: str,
        center_lat: float,
        center_lon: float,
        radius_m: int = 1000
    ) -> List[BuildingTransaction]:
        """
        ê±´ì¶•ë¬¼ ë§¤ë§¤ì‚¬ë¡€ ì¡°íšŒ (ì˜¤í”¼ìŠ¤í…”, ì—°ë¦½ë‹¤ì„¸ëŒ€, ë‹¨ë…ë‹¤ê°€êµ¬ í†µí•©) (ìºì‹± ì§€ì›)
        
        Args:
            lawd_cd: ë²•ì •ë™ì½”ë“œ
            deal_ymd: ê±°ë˜ë…„ì›” (YYYYMM)
            center_lat: ì¤‘ì‹¬ ìœ„ë„
            center_lon: ì¤‘ì‹¬ ê²½ë„
            radius_m: ê²€ìƒ‰ ë°˜ê²½ (ë¯¸í„°)
        
        Returns:
            BuildingTransaction ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"ğŸ¢ Fetching building transactions: lawd={lawd_cd}, date={deal_ymd}")
        
        # Try cache first
        if self.cache_enabled:
            cached_data = self.cache.get('building', lawd_cd, deal_ymd)
            if cached_data:
                transactions = [BuildingTransaction(**t) for t in cached_data]
                logger.info(f"   âœ… Loaded {len(transactions)} building transactions from cache")
                return transactions[:10]
        
        all_transactions = []
        
        # Fetch from all 3 building APIs
        endpoints = [
            (self.OFFICETEL_ENDPOINT, 'ì˜¤í”¼ìŠ¤í…”'),
            (self.TOWNHOUSE_ENDPOINT, 'ì—°ë¦½ë‹¤ì„¸ëŒ€'),
            (self.SINGLEHOUSE_ENDPOINT, 'ë‹¨ë…ë‹¤ê°€êµ¬')
        ]
        
        for endpoint, building_type in endpoints:
            params = {
                'serviceKey': self.api_key,
                'LAWD_CD': lawd_cd,
                'DEAL_YMD': deal_ymd,
                'numOfRows': '100',
                'pageNo': '1'
            }
            
            try:
                async with httpx.AsyncClient(timeout=30.0) as client:
                    response = await client.get(endpoint, params=params)
                    response.raise_for_status()
                    
                    items = self._parse_xml_response(response.text)
                    logger.info(f"   Retrieved {len(items)} {building_type} records")
                    
                    for item in items:
                        try:
                            # Extract data
                            area = float(item.get('hscpAr', '0') or item.get('plottgAr', '0'))  # ì „ìš©ë©´ì  or ëŒ€ì§€ë©´ì 
                            price = int(item.get('dealAmount', '0').replace(',', '')) * 10000
                            
                            if area <= 0 or price <= 0:
                                continue
                            
                            unit = price / area
                            
                            # Build address
                            sgg_nm = item.get('sggNm', '')
                            umd_nm = item.get('umdNm', '')
                            jibun = item.get('jibun', '')
                            building_name = item.get('aptNm', '') or item.get('houseNm', '') or ''
                            address = f"{sgg_nm} {umd_nm} {jibun}".strip()
                            
                            # Deal date
                            deal_year = item.get('dealYear', '')
                            deal_month = item.get('dealMonth', '').zfill(2)
                            deal_day = item.get('dealDay', '').zfill(2)
                            deal_date = f"{deal_year}.{deal_month}.{deal_day}"
                            
                            all_transactions.append(BuildingTransaction(
                                name=building_name or address,
                                address=address,
                                area_m2=area,
                                price_krw=price,
                                unit_krw_m2=unit,
                                deal_date=deal_date,
                                building_type=building_type
                            ))
                            
                        except Exception as e:
                            logger.warning(f"Failed to parse {building_type} item: {e}")
                            continue
                            
            except Exception as e:
                logger.error(f"âŒ {building_type} API failed: {e}")
                continue
        
        # Sort by date (most recent first) and take top 10
        all_transactions.sort(key=lambda x: x.deal_date, reverse=True)
        top_transactions = all_transactions[:10]
        
        logger.info(f"   âœ… Parsed {len(top_transactions)} building transactions total")
        if top_transactions:
            avg_unit = sum(t.unit_krw_m2 for t in top_transactions) / len(top_transactions)
            logger.info(f"   ğŸ“Š Average building price: {avg_unit/10000:.0f}ë§Œì›/ã¡")
        
        # Save to cache
        if self.cache_enabled and top_transactions:
            cache_data = [t.to_dict() for t in top_transactions]
            self.cache.set('building', lawd_cd, deal_ymd, cache_data)
        
        return top_transactions
    
    async def fetch_comparables(
        self,
        address: str,
        lawd_cd: str = None,
        radius_m: int = 1000
    ) -> Tuple[List[LandTransaction], List[BuildingTransaction]]:
        """
        ì£¼ì†Œ ê¸°ë°˜ ì‹¤ê±°ë˜ê°€ í†µí•© ì¡°íšŒ
        
        Args:
            address: ë¶„ì„ ëŒ€ìƒ ì£¼ì†Œ
            lawd_cd: ë²•ì •ë™ì½”ë“œ (Noneì´ë©´ ì£¼ì†Œì—ì„œ ì¶”ì¶œ)
            radius_m: ê²€ìƒ‰ ë°˜ê²½
        
        Returns:
            (í† ì§€ ê±°ë˜ì‚¬ë¡€ 10ê±´, ê±´ì¶•ë¬¼ ë§¤ë§¤ì‚¬ë¡€ 10ê±´)
        """
        logger.info("=" * 80)
        logger.info(f"ğŸ” Fetching real transaction comparables for: {address}")
        logger.info("=" * 80)
        
        # Get coordinates from address
        try:
            from app.services.kakao_service import KakaoService
            kakao = KakaoService()
            coord = await kakao.address_to_coordinates(address)
            center_lat = coord['y']
            center_lon = coord['x']
            logger.info(f"ğŸ“ Coordinates: lat={center_lat:.6f}, lon={center_lon:.6f}")
        except Exception as e:
            logger.error(f"Failed to get coordinates: {e}")
            center_lat = 37.5665
            center_lon = 126.9780
        
        # Extract lawd_cd from address if not provided
        if lawd_cd is None:
            if 'ì„œìš¸' in address:
                lawd_cd = '11'
            elif 'ê²½ê¸°' in address:
                lawd_cd = '41'
            elif 'ì¸ì²œ' in address:
                lawd_cd = '28'
            else:
                lawd_cd = '11'  # Default to Seoul
        
        # Get deal_ymd for last year
        last_year = (datetime.now() - timedelta(days=365)).strftime('%Y%m')
        
        # Fetch land and building transactions concurrently
        land_task = self.fetch_land_transactions(lawd_cd, last_year, center_lat, center_lon, radius_m)
        building_task = self.fetch_building_transactions(lawd_cd, last_year, center_lat, center_lon, radius_m)
        
        land_comps, building_comps = await asyncio.gather(land_task, building_task)
        
        logger.info("=" * 80)
        logger.info(f"âœ… Comparables fetched:")
        logger.info(f"   ğŸï¸  Land: {len(land_comps)} transactions")
        logger.info(f"   ğŸ¢ Building: {len(building_comps)} transactions")
        logger.info("=" * 80)
        
        return land_comps, building_comps


# Test function
async def test_api():
    """API í…ŒìŠ¤íŠ¸"""
    api = RealTransactionAPI()
    
    test_address = "ì„œìš¸íŠ¹ë³„ì‹œ ë§ˆí¬êµ¬ ì›”ë“œì»µë¶ë¡œ 120"
    land_comps, building_comps = await api.fetch_comparables(test_address)
    
    print("\n" + "=" * 80)
    print("ğŸ“Š Test Results")
    print("=" * 80)
    
    print(f"\nğŸï¸  Land Transactions ({len(land_comps)}ê°œ):")
    for i, comp in enumerate(land_comps[:3], 1):
        print(f"   {i}. {comp.address}")
        print(f"      ë©´ì : {comp.area_m2:.1f}ã¡, ë‹¨ê°€: {comp.unit_krw_m2/10000:.0f}ë§Œì›/ã¡")
    
    print(f"\nğŸ¢ Building Transactions ({len(building_comps)}ê°œ):")
    for i, comp in enumerate(building_comps[:3], 1):
        print(f"   {i}. {comp.name} ({comp.building_type})")
        print(f"      ë©´ì : {comp.area_m2:.1f}ã¡, ë‹¨ê°€: {comp.unit_krw_m2/10000:.0f}ë§Œì›/ã¡")
    
    if land_comps:
        avg_land = sum(c.unit_krw_m2 for c in land_comps) / len(land_comps)
        print(f"\nğŸ“Š í‰ê·  í† ì§€ ë‹¨ê°€: {avg_land/10000:.0f}ë§Œì›/ã¡")
    
    if building_comps:
        avg_bld = sum(c.unit_krw_m2 for c in building_comps) / len(building_comps)
        print(f"ğŸ“Š í‰ê·  ê±´ë¬¼ ë‹¨ê°€: {avg_bld/10000:.0f}ë§Œì›/ã¡")


if __name__ == '__main__':
    asyncio.run(test_api())

"""
LH Notice Loader - ZeroSite Land Report v5.0
Google Driveì—ì„œ LH ê³µê³ ë¬¸ PDFë¥¼ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ê³  ê·œì¹™ ì¶”ì¶œ
"""

import os
import re
import json
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from pathlib import Path
import asyncio


class LHNoticeLoader:
    """LH ê³µê³ ë¬¸ ìë™ ë¡œë” (Google Drive ì—°ë™)"""
    
    def __init__(self, storage_dir: str = "data/lh_notices"):
        """
        ì´ˆê¸°í™”
        
        Args:
            storage_dir: PDF ë° JSON ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        self.auto_rules_dir = Path("data/lh_rules_auto")
        self.auto_rules_dir.mkdir(parents=True, exist_ok=True)
        
        self.history_file = self.storage_dir / "processing_history.json"
        
        # Google Drive ì„¤ì •
        self.drive_folder_id = os.getenv("GOOGLE_DRIVE_FOLDER_ID", "13luANIq_cQ7KbzxVqb4QyG2r_q8-KaVv")
        self.credentials_path = os.getenv("GOOGLE_DRIVE_CREDENTIALS_PATH", "")
        
        # v2.0 íŒŒì¼ëª… íŒ¨í„´ (ë” ìœ ì—°í•œ íŒ¨í„´)
        self.filename_patterns = [
            # íŒ¨í„´ 1: ì„œìš¸25-8ì°¨ë¯¼ê°„ì‹ ì¶•ë§¤ì…ì•½ì •ë°©ì‹ê³µê³ ë¬¸.pdf
            r"(?P<region>[ê°€-í£]+)(?P<year>\d{2,4})-(?P<round>\d+)ì°¨",
            # íŒ¨í„´ 2: ê²½ê¸°24-3ì°¨_ê³µê³ ë¬¸_ìµœì¢….pdf
            r"(?P<region>[ê°€-í£]+)(?P<year>\d{2,4})-(?P<round>\d+)ì°¨.*ê³µê³ ",
            # íŒ¨í„´ 3: ë¶€ì‚°_2025_12ì°¨_ê³µê³ .pdf
            r"(?P<region>[ê°€-í£]+)_(?P<year>\d{4})_(?P<round>\d+)ì°¨",
        ]
        
    def _normalize_year(self, year_str: str) -> int:
        """ì—°ë„ ì •ê·œí™” (2ìë¦¬ â†’ 4ìë¦¬)"""
        year = int(year_str)
        if year < 100:
            year += 2000
        return year
    
    def parse_filename(self, filename: str) -> Optional[Dict[str, Any]]:
        """
        íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ (v2.0 improved)
        
        Args:
            filename: PDF íŒŒì¼ëª…
            
        Returns:
            ì¶”ì¶œëœ ì •ë³´ (region, year, round) ë˜ëŠ” None
        """
        for pattern in self.filename_patterns:
            match = re.search(pattern, filename)
            if match:
                groups = match.groupdict()
                year = self._normalize_year(groups["year"])
                round_num = groups["round"]
                
                return {
                    "region": groups["region"],
                    "year": year,
                    "round": f"{round_num}ì°¨",
                    "version_id": f"{year}_{round_num}ì°¨",
                    "filename": filename
                }
        
        return None
    
    async def sync_from_drive(self) -> Dict[str, Any]:
        """
        Google Driveì—ì„œ LH ê³µê³ ë¬¸ ë™ê¸°í™”
        
        Returns:
            ë™ê¸°í™” ê²°ê³¼ (synced_files, new_versions, failed_files)
        """
        try:
            # Google Drive API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            if not self.credentials_path or not os.path.exists(self.credentials_path):
                return {
                    "status": "error",
                    "message": "Google Drive credentials not configured. Set GOOGLE_DRIVE_CREDENTIALS_PATH environment variable.",
                    "synced_files": 0,
                    "new_versions": [],
                    "failed_files": []
                }
            
            from google.oauth2 import service_account
            from googleapiclient.discovery import build
            from googleapiclient.http import MediaIoBaseDownload
            import io
            
            # ì¸ì¦
            credentials = service_account.Credentials.from_service_account_file(
                self.credentials_path,
                scopes=['https://www.googleapis.com/auth/drive.readonly']
            )
            
            service = build('drive', 'v3', credentials=credentials)
            
            # í´ë” ë‚´ PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            query = f"'{self.drive_folder_id}' in parents and mimeType='application/pdf' and trashed=false"
            results = service.files().list(
                q=query,
                fields="files(id, name, modifiedTime)",
                orderBy="modifiedTime desc"
            ).execute()
            
            files = results.get('files', [])
            
            if not files:
                return {
                    "status": "success",
                    "message": "No PDF files found in Drive folder",
                    "synced_files": 0,
                    "new_versions": [],
                    "failed_files": []
                }
            
            # ì²˜ë¦¬ ì´ë ¥ ë¡œë“œ
            history = self._load_processing_history()
            
            synced_count = 0
            new_versions = []
            failed_files = []
            
            for file in files:
                file_id = file['id']
                filename = file['name']
                
                # íŒŒì¼ëª… íŒŒì‹±
                file_info = self.parse_filename(filename)
                if not file_info:
                    print(f"âš ï¸ íŒŒì¼ëª… í˜•ì‹ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŒ: {filename}")
                    failed_files.append({"filename": filename, "reason": "Unrecognized filename format"})
                    continue
                
                # ì´ë¯¸ ì²˜ë¦¬í•œ íŒŒì¼ì¸ì§€ í™•ì¸
                if filename in history.get("processed_files", []):
                    print(f"â­ï¸  ì´ë¯¸ ì²˜ë¦¬ë¨: {filename}")
                    continue
                
                try:
                    print(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘: {filename}")
                    
                    # PDF ë‹¤ìš´ë¡œë“œ
                    request = service.files().get_media(fileId=file_id)
                    pdf_path = self.storage_dir / filename
                    
                    fh = io.BytesIO()
                    downloader = MediaIoBaseDownload(fh, request)
                    
                    done = False
                    while not done:
                        status, done = downloader.next_chunk()
                    
                    # íŒŒì¼ ì €ì¥
                    with open(pdf_path, 'wb') as f:
                        f.write(fh.getvalue())
                    
                    print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {pdf_path}")
                    
                    # PDFì—ì„œ ê·œì¹™ ì¶”ì¶œ
                    rules = await self.process_notice_file(str(pdf_path), file_info)
                    
                    if rules:
                        new_versions.append(file_info["version_id"])
                        synced_count += 1
                        
                        # ì²˜ë¦¬ ì´ë ¥ì— ì¶”ê°€
                        history.setdefault("processed_files", []).append(filename)
                        history.setdefault("versions", []).append({
                            "version_id": file_info["version_id"],
                            "filename": filename,
                            "processed_at": datetime.now().isoformat(),
                            "rules_count": len(rules.get("rules", {}))
                        })
                    
                except Exception as e:
                    print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {filename} - {e}")
                    failed_files.append({"filename": filename, "reason": str(e)})
            
            # ì²˜ë¦¬ ì´ë ¥ ì €ì¥
            self._save_processing_history(history)
            
            return {
                "status": "success",
                "synced_files": synced_count,
                "new_versions": new_versions,
                "failed_files": failed_files,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": str(e),
                "synced_files": 0,
                "new_versions": [],
                "failed_files": []
            }
    
    async def process_notice_file(
        self, 
        pdf_path: str, 
        file_info: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        PDF íŒŒì¼ì—ì„œ LH ê·œì¹™ ì¶”ì¶œ ë° JSON ìƒì„±
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            file_info: íŒŒì¼ ì •ë³´ (region, year, round)
            
        Returns:
            ì¶”ì¶œëœ ê·œì¹™ ë˜ëŠ” None
        """
        try:
            # PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = self._extract_text_from_pdf(pdf_path)
            if not text:
                print(f"âš ï¸ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ: {pdf_path}")
                return None
            
            # ê·œì¹™ ì¶”ì¶œ
            rules = self._extract_rules_from_text(text, file_info)
            
            # JSON ì €ì¥
            json_path = self.auto_rules_dir / f"{file_info['version_id']}.json"
            self._save_rules_to_json(rules, json_path)
            
            print(f"âœ… ê·œì¹™ ì¶”ì¶œ ì™„ë£Œ: {json_path}")
            
            # Version Managerì— ë“±ë¡ (ì„ íƒì‚¬í•­)
            # self._register_with_version_manager(file_info["version_id"], str(json_path))
            
            return rules
            
        except Exception as e:
            print(f"âŒ PDF ì²˜ë¦¬ ì˜¤ë¥˜: {pdf_path} - {e}")
            return None
    
    def _extract_text_from_pdf(self, pdf_path: str) -> str:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            import pdfplumber
            
            text = ""
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n\n"
            
            return text
            
        except ImportError:
            print("âš ï¸ pdfplumberê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install pdfplumber")
            return ""
        except Exception as e:
            print(f"âš ï¸ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def _extract_rules_from_text(
        self, 
        text: str, 
        file_info: Dict[str, Any]
    ) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ì—ì„œ LH ê·œì¹™ ì¶”ì¶œ"""
        rules = {
            "version": file_info["version_id"],
            "region": file_info["region"],
            "year": file_info["year"],
            "round": file_info["round"],
            "effective_date": f"{file_info['year']}-01-01",  # ê¸°ë³¸ê°’
            "rules": {},
            "source_file": file_info["filename"],
            "parsed_at": datetime.now().isoformat(),
            "parser_version": "v5.0"
        }
        
        # ì£¼ê±° ìœ í˜• íŒ¨í„´
        housing_types = ["ì²­ë…„", "ì‹ í˜¼Â·ì‹ ìƒì•„", "ë‹¤ìë…€", "ê³ ë ¹ì", "ì¼ë°˜", "ë“ ë“ ì „ì„¸"]
        
        for housing_type in housing_types:
            # í•´ë‹¹ ìœ í˜• ê´€ë ¨ í…ìŠ¤íŠ¸ ì°¾ê¸°
            type_pattern = rf"{housing_type}.*?(\d+)í‰?ã¡?\s*ì´ìƒ"
            matches = re.finditer(type_pattern, text, re.IGNORECASE)
            
            for match in matches:
                area_str = match.group(1)
                
                try:
                    min_area = float(area_str.replace(',', ''))
                    
                    rules["rules"][housing_type] = {
                        "min_land_area_sqm": min_area,
                        "max_unit_area_sqm": self._get_default_unit_area(housing_type),
                        "criteria": [
                            f"{housing_type} ìœ í˜• ê¸°ì¤€",
                            f"ìµœì†Œ í† ì§€ë©´ì : {min_area}ã¡"
                        ]
                    }
                    
                    break  # ì²« ë²ˆì§¸ ë§¤ì¹˜ë§Œ ì‚¬ìš©
                    
                except ValueError:
                    continue
        
        return rules
    
    def _get_default_unit_area(self, housing_type: str) -> float:
        """ìœ í˜•ë³„ ê¸°ë³¸ ì „ìš©ë©´ì  (ã¡)"""
        defaults = {
            "ì²­ë…„": 40,
            "ì‹ í˜¼Â·ì‹ ìƒì•„": 60,
            "ë‹¤ìë…€": 85,
            "ê³ ë ¹ì": 40,
            "ì¼ë°˜": 85,
            "ë“ ë“ ì „ì„¸": 85
        }
        return defaults.get(housing_type, 60)
    
    def _save_rules_to_json(self, rules: Dict[str, Any], json_path: Path):
        """ê·œì¹™ì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(rules, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ JSON ì €ì¥ë¨: {json_path}")
    
    def _load_processing_history(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ ì´ë ¥ ë¡œë“œ"""
        if self.history_file.exists():
            with open(self.history_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _save_processing_history(self, history: Dict[str, Any]):
        """ì²˜ë¦¬ ì´ë ¥ ì €ì¥"""
        with open(self.history_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
    
    def list_processed_notices(self) -> List[Dict[str, Any]]:
        """ì²˜ë¦¬ëœ ê³µê³ ë¬¸ ëª©ë¡ ë°˜í™˜"""
        history = self._load_processing_history()
        return history.get("versions", [])
    
    def get_notice_rules(self, version_id: str) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • ë²„ì „ì˜ ê·œì¹™ ê°€ì ¸ì˜¤ê¸°"""
        json_path = self.auto_rules_dir / f"{version_id}.json"
        
        if json_path.exists():
            with open(json_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        return None


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_notice_loader = None

def get_notice_loader() -> LHNoticeLoader:
    """Notice Loader ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _notice_loader
    if _notice_loader is None:
        _notice_loader = LHNoticeLoader()
    return _notice_loader

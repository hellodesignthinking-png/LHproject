"""
FastAPI ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse, RedirectResponse
from fastapi.staticfiles import StaticFiles
from contextlib import asynccontextmanager
import uuid
from datetime import datetime
from pathlib import Path
from typing import Optional

from app.config import get_settings
from app.schemas import (
    LandAnalysisRequest,
    LandAnalysisResponse,
    ErrorResponse,
    UnitType,
    UnitTypeScore,
    MultiParcelResponse,
    ParcelAnalysisResult
)
from app.services.analysis_engine import AnalysisEngine
from app.services.report_generator import ProfessionalReportGenerator
from app.services.advanced_report_generator import ExpertReportGenerator
from app.services.lh_official_report_generator import LHOfficialReportGenerator
from app.services.lh_report_generator_v7_2 import LHReportGeneratorV72
from app.services.lh_report_generator_v7_5_final import LHReportGeneratorV75Final
from app.services.report_field_mapper_v7_2_complete import ReportFieldMapperV72Complete
from app.services.sheets_service import get_sheets_service
from app.services.lh_notice_loader import LHNoticeLoader
from app.services.dashboard_builder import DashboardBuilder
# âœ¨ v8.5: Import new financial, visualization, and LH criteria engines
from app.services.financial_engine_v7_4 import FinancialEngine
from app.services.visualization_engine_v85 import VisualizationEngineV85
from app.services.lh_criteria_checker_v85 import LHCriteriaCheckerV85

# âœ¨ v7.2: Import new Report Engine v7.2 router
from app.routers.report_v7_2 import router as report_v72_router

# âœ¨ v9.0: Import Analysis API v9.0 router
from app.api.endpoints.analysis_v9_0 import router as analysis_v90_router

# âœ¨ v9.1: Import Analysis API v9.1 router
from app.api.endpoints.analysis_v9_1 import router as analysis_v91_router

# âœ¨ v9.1 REAL: Import REAL working version
from app.api.endpoints.analysis_v9_1_REAL import router as analysis_v91_real_router

# âœ¨ MVP: Import MVP Analysis router
from app.api.endpoints.mvp_analyze import router as mvp_router

# âœ¨ v11.0 ENHANCEMENTS: Import middleware and utilities
from app.middleware.rate_limiter import RateLimiter, RateLimitConfig
from app.middleware.cache_manager import cache_manager, start_cache_cleanup_task
from app.i18n.translator import translator
import asyncio

settings = get_settings()

# LH ê³µì‹ 7ê°œ ìœ í˜• ì •ë³´ ë§¤í•‘
HOUSING_TYPE_INFO = {
    "ì²­ë…„": {"size": "30ã¡", "í‰": "9í‰"},
    "ì‹ í˜¼Â·ì‹ ìƒì•„ I": {"size": "45ã¡", "í‰": "14í‰"},
    "ì‹ í˜¼Â·ì‹ ìƒì•„ II": {"size": "55ã¡", "í‰": "17í‰"},
    "ë‹¤ìë…€": {"size": "65ã¡", "í‰": "20í‰"},
    "ê³ ë ¹ì": {"size": "40ã¡", "í‰": "12í‰"},
    "ì¼ë°˜": {"size": "85ã¡", "í‰": "26í‰"},
    "ë“ ë“ ì „ì„¸": {"size": "85ã¡", "í‰": "26í‰"}
}


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘/ì¢…ë£Œ ì‹œ ì‹¤í–‰"""
    print("=" * 60)
    print("ğŸš€ ZeroSite v11.0 HYBRID v2 ì‹œìŠ¤í…œ ì‹œì‘")
    print("=" * 60)
    print(f"ğŸ“ í™˜ê²½: {'ê°œë°œ' if settings.debug else 'ìš´ì˜'}")
    print(f"ğŸ”‘ API Keys ë¡œë“œë¨")
    print(f"ğŸ›¡ï¸  Rate Limiting: Enabled")
    print(f"ğŸ’¾ Cache: In-Memory (Ready)")
    print(f"ğŸŒ Multi-language: Korean + English")
    print(f"âœ… All Enhancements: Active")
    print("=" * 60)
    
    # Start background tasks
    cleanup_task = asyncio.create_task(start_cache_cleanup_task())
    
    yield
    
    # Cleanup
    cleanup_task.cancel()
    print("=" * 60)
    print("ğŸ‘‹ ì‹œìŠ¤í…œ ì¢…ë£Œ")
    print("=" * 60)


app = FastAPI(
    title="ZeroSite v11.0 HYBRID v2 - LH í† ì§€ì§„ë‹¨ ì‹œìŠ¤í…œ",
    description="""
    ğŸ¯ ZeroSite v11.0 HYBRID v2 Edition
    
    Features:
    - ğŸ¤– 5 AI Engines (LH Score, Decision, Unit-Type, Feasibility, Pseudo Data)
    - ğŸ“Š 100-point LH Scoring System
    - ğŸ¯ GO/REVIEW/NO-GO Decision Engine  
    - ğŸ˜ï¸ 5 Unit Types Ã— 6 Criteria Analysis
    - âœï¸ v7.5-style Professional Narratives
    - ğŸŒ Multi-language Support (Korean + English)
    - ğŸ›¡ï¸ Rate Limiting & Caching
    - ğŸ“„ ~26-page Government-grade Reports
    
    Status: 100% Complete | Production Ready
    """,
    version="11.0-HYBRID-v2",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ìš´ì˜ í™˜ê²½ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ë§Œ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# âœ¨ v11.0: Add Rate Limiting Middleware
# Note: RateLimiter uses default configuration from its __init__
# For production, it uses strict limits; for development, lenient limits
app.add_middleware(RateLimiter)

# âœ¨ v7.2: Include Report Engine v7.2 router
app.include_router(report_v72_router)

# âœ¨ v9.0: Include Analysis API v9.0 router
app.include_router(analysis_v90_router)

# âœ¨ v9.1: Include Analysis API v9.1 router
app.include_router(analysis_v91_router)

# âœ¨ v9.1 REAL: Include REAL working version router
app.include_router(analysis_v91_real_router)

# âœ¨ MVP: Include MVP Analysis router
app.include_router(mvp_router)

# ì •ì  íŒŒì¼ ì„œë¹™
static_path = Path(__file__).parent.parent / "static"
if static_path.exists():
    app.mount("/static", StaticFiles(directory=str(static_path)), name="static")

# âœ¨ v9.0: Frontend v9.0 ì„œë¹™
frontend_v9_path = Path(__file__).parent.parent / "frontend_v9"
if frontend_v9_path.exists():
    app.mount("/v9", StaticFiles(directory=str(frontend_v9_path), html=True), name="frontend_v9")


@app.get("/")
async def root():
    """ë©”ì¸ í˜ì´ì§€ - Admin Dashboardë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ (v11.0 HYBRID v2)"""
    # v11.0 HYBRID v2 Admin Dashboardë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
    return RedirectResponse(url="/static/admin_dashboard.html", status_code=302)


@app.get("/v11")
async def root_v11():
    """v11.0 HYBRID v2 Admin Dashboard"""
    return RedirectResponse(url="/static/admin_dashboard.html", status_code=302)


@app.get("/v9-legacy")
async def root_v9_legacy():
    """Legacy v9.1 REAL UI (êµ¬ë²„ì „ í˜¸í™˜ì„±)"""
    # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì¶”ê°€í•˜ì—¬ ë¸Œë¼ìš°ì € ìºì‹œ ìš°íšŒ
    timestamp = int(datetime.now().timestamp())
    return RedirectResponse(url=f"/v9/index_REAL.html?v={timestamp}", status_code=302)


@app.get("/v7")
async def root_v7():
    """v7.0 ì›¹ ì¸í„°í˜ì´ìŠ¤"""
    index_path = static_path / "index.html"
    if index_path.exists():
        return FileResponse(str(index_path))
    
    # íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ JSON ì‘ë‹µ
    return {
        "service": "LH í† ì§€ì§„ë‹¨ ìë™í™” ì‹œìŠ¤í…œ",
        "version": "1.0.0",
        "status": "running",
        "timestamp": datetime.now().isoformat()
    }


@app.get("/health")
async def health_check():
    """ìƒì„¸ í—¬ìŠ¤ ì²´í¬ (v11.0 Enhanced)"""
    cache_stats = cache_manager.get_stats()
    
    return {
        "status": "healthy",
        "version": "11.0-HYBRID-v2",
        "apis": {
            "kakao": "configured" if settings.kakao_rest_api_key else "missing",
            "land_regulation": "configured" if settings.land_regulation_api_key else "missing",
            "mois": "configured" if settings.mois_api_key else "missing"
        },
        "enhancements": {
            "rate_limiting": "enabled",
            "caching": "enabled",
            "multi_language": "enabled (ko, en)",
            "admin_dashboard": "enabled"
        },
        "cache_stats": {
            "total_entries": cache_stats["total_entries"],
            "hit_rate": f"{cache_stats['hit_rate_percent']}%",
            "hits": cache_stats["hits"],
            "misses": cache_stats["misses"]
        },
        "timestamp": datetime.now().isoformat()
    }


@app.post(
    "/api/analyze-land",
    response_model=LandAnalysisResponse,
    responses={
        400: {"model": ErrorResponse},
        500: {"model": ErrorResponse}
    }
)
async def analyze_land(request: LandAnalysisRequest):
    """
    í† ì§€ ì¢…í•© ë¶„ì„ API
    
    - **address**: ë¶„ì„í•  í† ì§€ì˜ ì£¼ì†Œ (ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ ì—­ì‚¼ë™ 123-45")
    - **land_area**: í† ì§€ ë©´ì (ã¡)
    - **unit_type**: (ì„ íƒì‚¬í•­) Noneì´ë©´ 7ê°€ì§€ ìœ í˜• ëª¨ë‘ ìë™ ë¶„ì„í•˜ì—¬ ì¶”ì²œ
    
    Returns:
        LandAnalysisResponse: ì¢…í•© ë¶„ì„ ê²°ê³¼
    """
    analysis_id = str(uuid.uuid4())[:8]
    
    try:
        print(f"\n{'='*60}")
        print(f"ğŸ†• ìƒˆë¡œìš´ ë¶„ì„ ìš”ì²­ [ID: {analysis_id}]")
        print(f"{'='*60}")
        print(f"ğŸ“ ì£¼ì†Œ: {request.address}")
        print(f"ğŸ“ ë©´ì : {request.land_area}ã¡")
        print(f"ğŸ  ìœ í˜•: {request.unit_type if request.unit_type else 'ì „ì²´ 7ê°œ ìœ í˜• ìë™ ë¶„ì„'}")
        print()
        
        # ë¶„ì„ ì—”ì§„
        engine = AnalysisEngine()
        
        # unit_typeì´ ì—†ìœ¼ë©´ 7ê°€ì§€ ëª¨ë‘ ë¶„ì„
        if not request.unit_type:
            print("ğŸ”„ 7ê°€ì§€ ìœ í˜• ì „ì²´ ë¶„ì„ ì‹œì‘...")
            all_types = list(UnitType)
            
            # âœ¨ í•œ ë²ˆë§Œ ë¶„ì„í•˜ì—¬ type_demand_scores ê°€ì ¸ì˜¤ê¸° (íš¨ìœ¨ì )
            temp_request = LandAnalysisRequest(
                address=request.address,
                land_area=request.land_area,
                unit_type=UnitType.YOUTH,  # ì„ì‹œë¡œ ì²­ë…„í˜• ì‚¬ìš© (ì „ì²´ ë¶„ì„ ë™ì¼)
                zone_type=request.zone_type,
                land_status=request.land_status,
                land_appraisal_price=request.land_appraisal_price
            )
            result = await engine.analyze_land(temp_request)
            
            # ğŸ”¥ type_demand_scoresì—ì„œ ìœ í˜•ë³„ ì°¨ë³„í™”ëœ ì ìˆ˜ ì‚¬ìš©
            type_demand_scores = result.get("type_demand_scores", {})
            print(f"  âœ“ ìœ í˜•ë³„ ìˆ˜ìš”ì ìˆ˜:")
            for unit_type, score in type_demand_scores.items():
                print(f"    - {unit_type}: {score:.1f}ì ")
            
            # ìœ í˜•ë³„ ì ìˆ˜ ë§¤í•‘ (ì˜ë¬¸ â†’ í•œê¸€)
            type_mapping = {
                "ì²­ë…„": UnitType.YOUTH.value,
                "ì‹ í˜¼Â·ì‹ ìƒì•„ I": UnitType.NEWLYWED_1.value,
                "ì‹ í˜¼Â·ì‹ ìƒì•„ II": UnitType.NEWLYWED_2.value,
                "ë‹¤ìë…€": UnitType.MULTI_CHILD.value,
                "ê³ ë ¹ì": UnitType.ELDERLY.value,
                "ì¼ë°˜": UnitType.GENERAL.value,
                "ë“ ë“ ì „ì„¸": UnitType.SECURE_JEONSE.value
            }
            
            # ê° ìœ í˜•ë³„ ì ìˆ˜ì™€ ì •ë³´ êµ¬ì„±
            all_results = []
            for kr_name, en_name in type_mapping.items():
                score = type_demand_scores.get(kr_name, 50.0)  # ê¸°ë³¸ê°’ 50ì 
                housing_info = HOUSING_TYPE_INFO.get(en_name, {})
                all_results.append({
                    "unit_type": en_name,
                    "score": score,
                    "size": housing_info.get("size", "N/A")
                })
            
            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            all_results.sort(key=lambda x: x["score"], reverse=True)
            
            # ìµœê³  ì ìˆ˜ ìœ í˜• ì„ íƒ
            best_result = all_results[0]
            recommended_type = best_result["unit_type"]
            
            print(f"  â””â”€ âœ… ì¶”ì²œ ìœ í˜•: {recommended_type} ({best_result['score']:.1f}ì )")
            
            # UnitTypeScore ëª©ë¡ ìƒì„±
            all_types_scores = [
                UnitTypeScore(
                    unit_type=r["unit_type"],
                    score=r["score"],
                    size=r["size"]
                )
                for r in all_results
            ]
            
        else:
            # ë‹¨ì¼ ìœ í˜• ë¶„ì„ (ê¸°ì¡´ ë°©ì‹)
            result = await engine.analyze_land(request)
            housing_info = HOUSING_TYPE_INFO.get(request.unit_type.value, {})
            recommended_type = request.unit_type.value
            
            demand_analysis = result["demand_analysis"]
            demand_score = demand_analysis.demand_score if hasattr(demand_analysis, 'demand_score') else demand_analysis.get("demand_score", 0)
            
            all_types_scores = [
                UnitTypeScore(
                    unit_type=request.unit_type.value,
                    score=demand_score,
                    size=housing_info.get("size", "N/A")
                )
            ]
        
        # âœ¨ v8.5: Calculate financial result using FinancialEngine
        print("ğŸ’° v8.5: Calculating financial metrics...")
        financial_engine = FinancialEngine()
        
        # Calculate unit type for financial analysis
        unit_type_for_financial = recommended_type if isinstance(recommended_type, str) else recommended_type.value
        
        # Run comprehensive financial analysis
        from app.services.financial_engine_v7_4 import run_full_financial_analysis
        financial_result = run_full_financial_analysis(
            land_area=request.land_area,
            address=request.address,
            unit_type=unit_type_for_financial,
            construction_type=getattr(request, 'construction_type', 'standard'),
            land_appraisal_price=request.land_appraisal_price  # ğŸ”¥ User-provided appraisal
        )
        
        print(f"  âœ“ Financial analysis complete:")
        print(f"    - Total CAPEX: {financial_result.get('summary', {}).get('total_investment', 0):,.0f} KRW")
        print(f"    - Unit Count: {financial_result.get('summary', {}).get('unit_count', 0)} units")
        print(f"    - Cap Rate: {financial_result.get('summary', {}).get('cap_rate', 0):.2f}%")
        print(f"    - IRR Range: {financial_result.get('summary', {}).get('irr_range', 'N/A')}")
        
        # ğŸ”¥ v8.6: CRITICAL FIX - Override v7.5 unit count with v8.5 financial engine units
        v8_5_unit_count = financial_result.get('summary', {}).get('unit_count', 0)
        if v8_5_unit_count > 0:
            print(f"  ğŸ”„ Synchronizing unit count:")
            
            # Get v7.5 building_capacity units safely
            bc = result.get("building_capacity")
            v7_5_units = bc.units if hasattr(bc, 'units') else (bc.get('units', 0) if isinstance(bc, dict) else 0)
            print(f"    - v7.5 building_capacity: {v7_5_units} units (DISCARDING)")
            print(f"    - v8.5 financial_result: {v8_5_unit_count} units (APPLYING)")
            
            # Override all unit count references with v8.5 value
            if isinstance(bc, dict):
                result["building_capacity"]["units"] = v8_5_unit_count
            elif hasattr(bc, 'units'):
                result["building_capacity"].units = v8_5_unit_count
            
            summ = result.get("summary")
            if isinstance(summ, dict):
                result["summary"]["estimated_units"] = v8_5_unit_count
            elif hasattr(summ, 'estimated_units'):
                result["summary"].estimated_units = v8_5_unit_count
            
            result["expected_units"] = v8_5_unit_count
            
            print(f"  âœ… Unit count synchronized to {v8_5_unit_count} units across all data structures")
        
        # âœ¨ v8.5: Calculate LH scores using v8.5 criteria checker
        print("ğŸ“Š v8.5: Evaluating LH criteria...")
        lh_checker_v85 = LHCriteriaCheckerV85()
        
        # Determine analysis mode based on unit count
        unit_count = financial_result.get('summary', {}).get('unit_count', 0)
        analysis_mode = 'LH_LINKED' if unit_count >= 50 else 'STANDARD'
        print(f"  âœ“ Analysis Mode: {analysis_mode} ({unit_count} units)")
        
        lh_scores = lh_checker_v85.evaluate_financial_feasibility(
            financial_result=financial_result,
            zone_info=result["zone_info"],
            building_capacity=result["building_capacity"],
            accessibility=result.get("demand_analysis", {})
        )
        
        print(f"  âœ“ LH Scores calculated:")
        print(f"    - Location: {lh_scores.get('location_score', 0):.1f}/35")
        print(f"    - Scale: {lh_scores.get('scale_score', 0):.1f}/20")
        print(f"    - Financial: {lh_scores.get('financial_score', 0):.1f}/40")
        print(f"    - Regulations: {lh_scores.get('regulations_score', 0):.1f}/15")
        print(f"    - Total: {lh_scores.get('total_score', 0):.1f}/110")
        
        # âœ¨ v8.5: Generate visualizations
        print("ğŸ¨ v8.5: Generating visualizations...")
        viz_engine = VisualizationEngineV85()
        visualizations = viz_engine.generate_all_visualizations(
            financial_result=financial_result,
            lh_scores=lh_scores,
            analysis_data=result
        )
        
        print(f"  âœ“ Generated {len(visualizations)} visualization datasets")
        
        # ì‘ë‹µ ìƒì„±
        response = LandAnalysisResponse(
            status="success",
            analysis_id=analysis_id,
            address=request.address,
            land_area=request.land_area,
            unit_type=recommended_type,
            recommended_unit_type=recommended_type,
            all_types_scores=all_types_scores,
            coordinates=result["coordinates"],
            zone_info=result["zone_info"],
            building_capacity=result["building_capacity"],
            risk_factors=result["risk_factors"],
            demographic_info=result["demographic_info"],
            demand_analysis=result["demand_analysis"],
            summary=result["summary"],
            report_text=None,
            pdf_url=f"/api/reports/{analysis_id}.pdf",
            grade_info=result.get("grade_info"),  # ë“±ê¸‰ ì •ë³´ ì¶”ê°€
            checklist=result.get("checklist", []),  # ì²´í¬ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
            checklist_details=result.get("checklist_details"),  # ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„¸ ì •ë³´ (PDFìš©)
            type_demand_scores=result.get("type_demand_scores", {}),  # âœ¨ v5.0: ìœ í˜•ë³„ ìˆ˜ìš”ì ìˆ˜
            corrected_input=result.get("corrected_input"),  # âœ¨ v5.0: AI ìë™ êµì •
            geo_optimization=result.get("geo_optimization"),  # âœ¨ v5.0: ì§€ë¦¬ ìµœì í™”
            # âœ¨ v8.5: Add new financial, LH scores, and visualization data
            financial_result=financial_result,  # ğŸ”¥ NEW: Complete financial analysis
            lh_scores=lh_scores,  # ğŸ”¥ NEW: v8.5 LH evaluation scores
            visualizations=visualizations,  # ğŸ”¥ NEW: Chart/graph data
            analysis_mode=analysis_mode,  # ğŸ”¥ NEW: LH_LINKED or STANDARD
            created_at=datetime.now()
        )
        
        # Google Sheetsì— ì €ì¥ (ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹¤í–‰)
        try:
            sheets_service = get_sheets_service()
            if sheets_service.enabled:
                print("ğŸ“Š Google Sheetsì— ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘...")
                
                # ë‹´ë‹¹ì ì •ë³´ ì¶”ì¶œ
                consultant_info = None
                if request.consultant:
                    consultant_info = {
                        "name": request.consultant.name,
                        "phone": request.consultant.phone,
                        "department": request.consultant.department,
                        "email": request.consultant.email
                    }
                
                # ë¶„ì„ ë°ì´í„° ì¤€ë¹„
                analysis_data = {
                    "address": request.address,
                    "land_area": request.land_area,
                    "zone_info": result["zone_info"].__dict__ if hasattr(result["zone_info"], '__dict__') else result["zone_info"],
                    "recommended_unit_type": recommended_type,
                    "demand_analysis": result["demand_analysis"].__dict__ if hasattr(result["demand_analysis"], '__dict__') else result["demand_analysis"],
                    "building_capacity": result["building_capacity"].__dict__ if hasattr(result["building_capacity"], '__dict__') else result["building_capacity"],
                    "risks": [r.__dict__ if hasattr(r, '__dict__') else r for r in result["risk_factors"]],
                    "report_path": f"/api/reports/{analysis_id}.pdf"
                }
                
                sheets_result = await sheets_service.save_analysis(analysis_data, consultant_info)
                
                if sheets_result.get("success"):
                    print(f"  âœ… Google Sheets ì €ì¥ ì™„ë£Œ (í–‰ {sheets_result.get('row_number')})")
                    if sheets_result.get("duplicate"):
                        print(f"  âš ï¸ ì¤‘ë³µ ê²½ê³ : ì´ í† ì§€ëŠ” ì´ì „ì— {sheets_result.get('duplicate_count')}íšŒ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤")
                        print(f"     ë¶„ì„ ë‚ ì§œ: {', '.join(sheets_result.get('duplicate_dates', []))}")
                else:
                    print(f"  âš ï¸ Google Sheets ì €ì¥ ì‹¤íŒ¨: {sheets_result.get('message')}")
        except Exception as e:
            print(f"âš ï¸ Google Sheets ì €ì¥ ì¤‘ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰): {e}")
        
        print(f"{'='*60}")
        print(f"âœ… ë¶„ì„ ì™„ë£Œ [ID: {analysis_id}]")
        print(f"{'='*60}\n")
        
        return response
        
    except ValueError as e:
        print(f"âŒ ìš”ì²­ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=400,
            detail={
                "status": "error",
                "error_code": "INVALID_REQUEST",
                "message": str(e)
            }
        )
    
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        
        raise HTTPException(
            status_code=500,
            detail={
                "status": "error",
                "error_code": "INTERNAL_ERROR",
                "message": "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "details": str(e) if settings.debug else None
            }
        )


@app.post(
    "/api/analyze-multi-parcel",
    response_model=LandAnalysisResponse,  # Import MultiParcelResponse at top
    responses={
        400: {"model": ErrorResponse},
        500: {"model": ErrorResponse}
    }
)
async def analyze_multi_parcel(request: dict):
    """
    âœ¨ v5.0: ë‹¤í•„ì§€ ë¶„ì„ API
    
    ì—¬ëŸ¬ í•„ì§€ë¥¼ ë™ì‹œì— ë¶„ì„í•˜ì—¬ ê°ê°ì˜ ì í•©ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.
    
    Request Body:
        - parcels: List[str] - í•„ì§€ ì£¼ì†Œ ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 10ê°œ)
        - land_area: float - ì´ í† ì§€ ë©´ì 
        - unit_type: Optional[str] - ì„¸ëŒ€ ìœ í˜•
        - lh_version: str - LH ê¸°ì¤€ ë²„ì „ (ê¸°ë³¸: "2024")
        
    Returns:
        MultiParcelResponse: ë‹¤í•„ì§€ ë¶„ì„ ê²°ê³¼
    """
    from app.schemas import MultiParcelResponse, ParcelAnalysisResult
    
    analysis_id = str(uuid.uuid4())[:8]
    
    try:
        print(f"\n{'='*60}")
        print(f"ğŸ†• ë‹¤í•„ì§€ ë¶„ì„ ìš”ì²­ [ID: {analysis_id}]")
        print(f"{'='*60}")
        
        # ìš”ì²­ íŒŒë¼ë¯¸í„° íŒŒì‹±
        parcels = request.get("parcels", [])
        land_area = request.get("land_area", 0)
        unit_type_str = request.get("unit_type")
        lh_version = request.get("lh_version", "2024")
        
        if not parcels or not isinstance(parcels, list):
            raise ValueError("í•„ì§€ ì£¼ì†Œ ë¦¬ìŠ¤íŠ¸(parcels)ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        if len(parcels) > 10:
            raise ValueError("ìµœëŒ€ 10ê°œ í•„ì§€ê¹Œì§€ ë¶„ì„ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        if land_area <= 0:
            raise ValueError("ìœ íš¨í•œ í† ì§€ ë©´ì ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        print(f"ğŸ“ í•„ì§€ ìˆ˜: {len(parcels)}ê°œ")
        print(f"ğŸ“ ì´ ë©´ì : {land_area}ã¡")
        print(f"ğŸ  ìœ í˜•: {unit_type_str or 'ì „ì²´ 7ê°œ ìœ í˜• ìë™ ë¶„ì„'}")
        print()
        
        # Unit type ë³€í™˜
        unit_type_obj = None
        if unit_type_str:
            unit_type_obj = UnitType(unit_type_str)
        
        # ë¶„ì„ ì—”ì§„
        engine = AnalysisEngine()
        
        # ê° í•„ì§€ë³„ë¡œ ë¶„ì„
        results = []
        successful_count = 0
        failed_count = 0
        
        for idx, parcel_address in enumerate(parcels, 1):
            print(f"ğŸ” í•„ì§€ {idx}/{len(parcels)}: {parcel_address}")
            
            try:
                # ê°œë³„ í•„ì§€ ë¶„ì„ ìš”ì²­ ìƒì„±
                parcel_request = LandAnalysisRequest(
                    address=parcel_address,
                    land_area=land_area / len(parcels),  # ë©´ì  ê· ë“± ë¶„ë°° (ì‹¤ì œë¡œëŠ” ê°œë³„ ì…ë ¥ í•„ìš”)
                    unit_type=unit_type_obj,
                    lh_version=lh_version
                )
                
                # ë¶„ì„ ì‹¤í–‰
                parcel_result = await engine.analyze_land(parcel_request)
                
                # ê²°ê³¼ ì €ì¥
                demand_score = parcel_result["demand_analysis"].demand_score
                building_capacity = parcel_result["building_capacity"].units
                
                result_obj = ParcelAnalysisResult(
                    address=parcel_address,
                    success=True,
                    coordinates=parcel_result["coordinates"],
                    demand_score=demand_score,
                    building_capacity=building_capacity,
                    risk_factors=parcel_result["risk_factors"],
                    summary=parcel_result["summary"]
                )
                
                results.append(result_obj)
                successful_count += 1
                print(f"  âœ… ë¶„ì„ ì™„ë£Œ: ìˆ˜ìš”ì ìˆ˜ {demand_score:.1f}ì , {building_capacity}ì„¸ëŒ€")
                
            except Exception as e:
                # ê°œë³„ í•„ì§€ ë¶„ì„ ì‹¤íŒ¨ ì²˜ë¦¬
                result_obj = ParcelAnalysisResult(
                    address=parcel_address,
                    success=False,
                    error_message=str(e)
                )
                results.append(result_obj)
                failed_count += 1
                print(f"  âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        # ì¶”ì²œ í•„ì§€ ì„ ì • (ì ìˆ˜ ê¸°ë°˜ ìƒìœ„ 3ê°œ)
        successful_results = [r for r in results if r.success and r.demand_score is not None]
        successful_results.sort(key=lambda x: x.demand_score, reverse=True)
        recommended_parcels = [r.address for r in successful_results[:3]]
        
        # í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ (ì„ íƒì‚¬í•­ - ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ìƒëµ)
        cluster_analysis = None
        if len(successful_results) >= 2:
            # í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ìˆ˜í–‰ ê°€ëŠ¥
            parcel_analyzer = engine.parcel_analyzer
            parcel_data = [
                {
                    "address": r.address,
                    "latitude": r.coordinates.latitude if r.coordinates else 0,
                    "longitude": r.coordinates.longitude if r.coordinates else 0,
                    "area": land_area / len(parcels),
                    "demand_score": r.demand_score,
                    "building_capacity": r.building_capacity
                }
                for r in successful_results
            ]
            
            clustering_result = parcel_analyzer.analyze_parcels(parcel_data)
            cluster_analysis = {
                "total_parcels": clustering_result.total_parcels,
                "clusters": [c.dict() for c in clustering_result.clusters],
                "recommended_cluster_id": clustering_result.recommended_cluster_id,
                "optimization_suggestions": clustering_result.optimization_suggestions
            }
        
        # ì‘ë‹µ ìƒì„±
        response = MultiParcelResponse(
            status="success",
            analysis_id=analysis_id,
            total_parcels=len(parcels),
            successful=successful_count,
            failed=failed_count,
            results=results,
            cluster_analysis=cluster_analysis,
            recommended_parcels=recommended_parcels,
            created_at=datetime.now()
        )
        
        print(f"\n{'='*60}")
        print(f"âœ… ë‹¤í•„ì§€ ë¶„ì„ ì™„ë£Œ [ID: {analysis_id}]")
        print(f"   ì„±ê³µ: {successful_count}ê°œ, ì‹¤íŒ¨: {failed_count}ê°œ")
        print(f"   ì¶”ì²œ í•„ì§€: {', '.join(recommended_parcels[:2])} ì™¸ {len(recommended_parcels)-2}ê°œ" if len(recommended_parcels) > 2 else f"   ì¶”ì²œ í•„ì§€: {', '.join(recommended_parcels)}")
        print(f"{'='*60}\n")
        
        return response
        
    except ValueError as e:
        print(f"âŒ ìš”ì²­ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=400,
            detail={
                "status": "error",
                "error_code": "INVALID_REQUEST",
                "message": str(e)
            }
        )
    
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        
        raise HTTPException(
            status_code=500,
            detail={
                "status": "error",
                "error_code": "INTERNAL_ERROR",
                "message": "ë‹¤í•„ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "details": str(e) if settings.debug else None
            }
        )


@app.post("/api/lh-notices/sync")
async def sync_lh_notices():
    """
    âœ¨ v5.0: LH ê³µê³ ë¬¸ Google Drive ë™ê¸°í™” API
    
    Google Driveì—ì„œ LH ê³µê³ ë¬¸ PDFë¥¼ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ê³ ,
    PDFì—ì„œ ê·œì¹™ì„ ì¶”ì¶œí•˜ì—¬ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Returns:
        ë™ê¸°í™” ê²°ê³¼ (synced_files, new_versions, failed_files)
    """
    from app.services.lh_notice_loader import get_notice_loader
    
    try:
        print(f"\n{'='*60}")
        print(f"ğŸ“¥ LH ê³µê³ ë¬¸ ë™ê¸°í™” ì‹œì‘")
        print(f"{'='*60}\n")
        
        loader = get_notice_loader()
        results = await loader.sync_from_drive()
        
        print(f"\n{'='*60}")
        print(f"âœ… LH ê³µê³ ë¬¸ ë™ê¸°í™” ì™„ë£Œ")
        print(f"   ë™ê¸°í™”: {results.get('synced_files', 0)}ê°œ")
        print(f"   ì‹ ê·œ ë²„ì „: {len(results.get('new_versions', []))}ê°œ")
        print(f"   ì‹¤íŒ¨: {len(results.get('failed_files', []))}ê°œ")
        print(f"{'='*60}\n")
        
        return results
        
    except Exception as e:
        print(f"âŒ LH ê³µê³ ë¬¸ ë™ê¸°í™” ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        
        raise HTTPException(
            status_code=500,
            detail={
                "status": "error",
                "error_code": "SYNC_ERROR",
                "message": "LH ê³µê³ ë¬¸ ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "details": str(e) if settings.debug else None
            }
        )


@app.get("/api/lh-notices/list")
async def list_lh_notices():
    """
    âœ¨ v5.0: ì²˜ë¦¬ëœ LH ê³µê³ ë¬¸ ëª©ë¡ ì¡°íšŒ API
    
    Returns:
        ì²˜ë¦¬ëœ ê³µê³ ë¬¸ ëª©ë¡
    """
    from app.services.lh_notice_loader import get_notice_loader
    
    try:
        loader = get_notice_loader()
        notices = loader.list_processed_notices()
        
        return {
            "status": "success",
            "total": len(notices),
            "notices": notices
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={
                "status": "error",
                "message": str(e)
            }
        )


@app.get("/api/lh-notices/{version_id}")
async def get_lh_notice_rules(version_id: str):
    """
    âœ¨ v5.0: íŠ¹ì • ë²„ì „ì˜ LH ê·œì¹™ ì¡°íšŒ API
    
    Args:
        version_id: ë²„ì „ ID (ì˜ˆ: "2024_8ì°¨")
        
    Returns:
        LH ê·œì¹™ ë°ì´í„°
    """
    from app.services.lh_notice_loader import get_notice_loader
    
    try:
        loader = get_notice_loader()
        rules = loader.get_notice_rules(version_id)
        
        if not rules:
            raise HTTPException(
                status_code=404,
                detail={
                    "status": "error",
                    "message": f"ê·œì¹™ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {version_id}"
                }
            )
        
        return {
            "status": "success",
            "version_id": version_id,
            "rules": rules
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={
                "status": "error",
                "message": str(e)
            }
        )


@app.get("/api/dashboard-data")
async def get_dashboard_data(analysis_id: Optional[str] = None):
    """
    âœ¨ v5.0: ëŒ€ì‹œë³´ë“œ ë°ì´í„° API
    
    Chart.js, Leaflet, Mapbox GL JSìš© ëŒ€ì‹œë³´ë“œ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        analysis_id: ë¶„ì„ ID (ì„ íƒì‚¬í•­, í˜„ì¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        
    Returns:
        ëŒ€ì‹œë³´ë“œ ë°ì´í„° (chart_co